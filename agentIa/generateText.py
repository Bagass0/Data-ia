"""
Agent IA avec Function Calling et ex√©cution multi-√©tapes
Utilise l'API Mistral AI pour g√©n√©rer du texte et ex√©cuter des actions
"""

import json
import os
import subprocess
import requests
from typing import Optional, List, Dict
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY")
DEFAULT_MODEL = "mistral-tiny"
DEFAULT_TEMPERATURE = 0.7
API_TIMEOUT = 30
SCRIPT_TIMEOUT = 30


def generateText(prompt: str, model: str = DEFAULT_MODEL, temperature: float = DEFAULT_TEMPERATURE, max_tokens: Optional[int] = None) -> str:
    """
    G√©n√®re du texte en utilisant l'API Mistral AI.
    
    Args:
        prompt: Le prompt √† envoyer √† l'API
        model: Le mod√®le √† utiliser
        temperature: Contr√¥le la cr√©ativit√© (0.0 √† 1.0)
        max_tokens: Limite le nombre de tokens
    
    Returns:
        Le texte g√©n√©r√© par l'API
    
    Raises:
        Exception: Si l'API retourne une erreur
    """
    if not MISTRAL_API_KEY:
        raise ValueError("Cl√© API Mistral manquante dans le fichier .env")
    
    url = "https://api.mistral.ai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature
    }
    
    if max_tokens is not None:
        data["max_tokens"] = max_tokens
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=API_TIMEOUT)
        
        if response.status_code == 200:
            result = response.json()
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            else:
                raise Exception("Structure de r√©ponse inattendue de l'API Mistral")
        else:
            error_msg = f"Erreur API Mistral: {response.status_code}"
            try:
                error_details = response.json()
                if "error" in error_details:
                    error_msg += f" - {error_details['error']}"
            except:
                error_msg += f" - {response.text}"
            raise Exception(error_msg)
    
    except requests.exceptions.RequestException as e:
        raise Exception(f"Erreur de connexion √† l'API Mistral: {str(e)}")


def writeFile(path: str, content: str) -> str:
    """
    √âcrit du contenu dans un fichier dans le dossier 'generated'.
    
    Args:
        path: Le chemin du fichier √† cr√©er (sera plac√© dans generated/)
        content: Le contenu √† √©crire
    
    Returns:
        Message de confirmation
    """
    try:
        # Cr√©er le dossier generated s'il n'existe pas
        generated_dir = "generated"
        if not os.path.exists(generated_dir):
            os.makedirs(generated_dir)
        
        # Construire le chemin complet dans le dossier generated
        full_path = os.path.join(generated_dir, path)
        
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"‚úÖ Fichier cr√©√© avec succ√®s : {full_path}"
    except Exception as e:
        return f"‚ùå Erreur lors de la cr√©ation du fichier : {str(e)}"


def launchPythonFile(path: str) -> str:
    """
    Lance un fichier Python depuis le dossier 'generated'.
    
    Args:
        path: Le chemin du fichier Python √† ex√©cuter
    
    Returns:
        Le r√©sultat de l'ex√©cution
    """
    try:
        # Normaliser le chemin - enlever les "generated/" en double
        if path.startswith("generated/") or path.startswith("generated\\"):
            # Le chemin contient d√©j√† generated/, on l'utilise tel quel
            full_path = path.replace("\\", "/")  # Normaliser les s√©parateurs
        else:
            # Ajouter generated/ devant
            generated_dir = "generated"
            full_path = os.path.join(generated_dir, path).replace("\\", "/")
        
        # V√©rifier que le fichier existe
        if not os.path.exists(full_path):
            # Essayer aussi sans le pr√©fixe generated/ au cas o√π
            alt_path = path
            if os.path.exists(alt_path):
                full_path = alt_path
            else:
                return f"‚ùå Fichier non trouv√© : {full_path} (aussi test√©: {alt_path})"
        
        result = subprocess.run(['python', full_path], capture_output=True, text=True, timeout=SCRIPT_TIMEOUT)
        if result.returncode == 0:
            return f"‚úÖ Ex√©cution r√©ussie :\n{result.stdout}"
        else:
            return f"‚ùå Erreur d'ex√©cution :\n{result.stderr}"
    except subprocess.TimeoutExpired:
        return "‚è±Ô∏è Timeout : Le script a pris trop de temps √† s'ex√©cuter"
    except Exception as e:
        return f"‚ùå Erreur lors du lancement : {str(e)}"


def readFile(path: str) -> str:
    """
    Lit le contenu d'un fichier depuis le dossier 'generated'.
    
    Args:
        path: Le chemin du fichier √† lire
    
    Returns:
        Le contenu du fichier ou un message d'erreur
    """
    try:
        # Normaliser le chemin - enlever les "generated/" en double
        if path.startswith("generated/") or path.startswith("generated\\"):
            # Le chemin contient d√©j√† generated/, on l'utilise tel quel
            full_path = path.replace("\\", "/")
        else:
            # Ajouter generated/ devant
            generated_dir = "generated"
            full_path = os.path.join(generated_dir, path).replace("\\", "/")
        
        # V√©rifier que le fichier existe
        if not os.path.exists(full_path):
            # Essayer aussi sans le pr√©fixe generated/ au cas o√π
            alt_path = path
            if os.path.exists(alt_path):
                full_path = alt_path
            else:
                return f"‚ùå Fichier non trouv√© : {full_path}"
        
        with open(full_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return f"‚úÖ Contenu du fichier {full_path} :\n{content}"
    except Exception as e:
        return f"‚ùå Erreur lors de la lecture du fichier : {str(e)}"


def stop() -> str:
    """
    Fonction pour arr√™ter l'agent.
    
    Returns:
        Message d'arr√™t
    """
    return "üõë Agent arr√™t√© - T√¢che termin√©e"


class Agent:
    """Agent IA avec capacit√© d'ex√©cution multi-√©tapes"""
    
    def __init__(self):
        self.available_functions = {
            "writeFile": writeFile,
            "launchPythonFile": launchPythonFile,
            "readFile": readFile,
            "stop": stop
        }
        self.execution_history = []
    
    def get_function_calling_prompt(self, user_message: str, history: List[str] = None) -> str:
        """
        Cr√©√© un prompt pour le function calling avec historique.
        
        Args:
            user_message: Le message de l'utilisateur
            history: Historique des actions pr√©c√©dentes
        
        Returns:
            Le prompt format√©
        """
        history_text = ""
        if history:
            history_text = f"\n\nHistorique des actions pr√©c√©dentes :\n" + "\n".join(history)
        
        return f"""Tu es un assistant qui peut utiliser des fonctions pour accomplir des t√¢ches complexes.

Fonctions disponibles :

1. writeFile(path, content)
   - Cr√©e un fichier avec le contenu sp√©cifi√©
   - path: chemin du fichier (string)
   - content: contenu √† √©crire (string)

2. launchPythonFile(path)
   - Lance un fichier Python
   - path: chemin du fichier Python (string)

3. readFile(path)
   - Lit le contenu d'un fichier
   - path: chemin du fichier (string)

4. stop()
   - Arr√™te l'agent quand la t√¢che est termin√©e
   - Aucun argument requis

Demande de l'utilisateur: "{user_message}"{history_text}

Si tu dois utiliser une fonction, r√©ponds UNIQUEMENT avec un JSON valide dans ce format :
{{
    "function_name": "nom_de_la_fonction",
    "arguments": {{
        "argument1": "valeur1",
        "argument2": "valeur2"
    }}
}}

Si la t√¢che est termin√©e, utilise la fonction "stop".
Si tu n'as pas besoin d'utiliser une fonction maintenant, r√©ponds normalement.

Ne r√©ponds QUE avec le JSON ou un texte normal, pas les deux."""

    def execute_function_call(self, function_name: str, arguments: Dict) -> str:
        """
        Ex√©cute une fonction bas√©e sur son nom et ses arguments.
        
        Args:
            function_name: Le nom de la fonction √† ex√©cuter
            arguments: Les arguments √† passer √† la fonction
        
        Returns:
            Le r√©sultat de l'ex√©cution
        """
        if function_name not in self.available_functions:
            return f"‚ùå Fonction inconnue : {function_name}"
        
        try:
            function = self.available_functions[function_name]
            if arguments:
                result = function(**arguments)
            else:
                result = function()
            return result
        except Exception as e:
            return f"‚ùå Erreur lors de l'ex√©cution de {function_name} : {str(e)}"

    def process_llm_response(self, response: str, step: int) -> tuple:
        """
        Traite la r√©ponse du LLM et ex√©cute les fonctions si n√©cessaire.
        
        Args:
            response: La r√©ponse du LLM
            step: Num√©ro de l'√©tape
        
        Returns:
            Tuple (r√©sultat, should_stop)
        """
        try:
            response_json = json.loads(response.strip())
            
            if "function_name" in response_json and "arguments" in response_json:
                function_name = response_json["function_name"]
                arguments = response_json.get("arguments", {})
                
                print(f"üîß √âtape {step}: Ex√©cution de la fonction : {function_name}")
                print(f"ÔøΩ Arguments : {arguments}")
                
                # Ex√©cuter la fonction
                result = self.execute_function_call(function_name, arguments)
                
                # Ajouter √† l'historique
                history_entry = f"√âtape {step}: {function_name}({arguments}) -> {result}"
                self.execution_history.append(history_entry)
                
                # V√©rifier si c'est la fonction stop
                should_stop = function_name == "stop"
                
                return result, should_stop
            else:
                return response, False
        except json.JSONDecodeError:
            # Si ce n'est pas du JSON, c'est une r√©ponse normale
            return response, False

    def run_agent(self, prompt: str, max_step: int = 10) -> List[str]:
        """
        Lance l'agent pour accomplir une t√¢che avec plusieurs √©tapes.
        
        Args:
            prompt: La demande initiale de l'utilisateur
            max_step: Nombre maximum d'√©tapes
        
        Returns:
            Liste des r√©sultats de chaque √©tape
        """
        print(f"üöÄ D√©marrage de l'agent pour : {prompt}")
        print(f"üìä Maximum {max_step} √©tapes")
        print("=" * 60)
        
        results = []
        self.execution_history = []
        
        for step in range(1, max_step + 1):
            print(f"\nüéØ √âTAPE {step}/{max_step}")
            print("-" * 30)
            
            # Cr√©er le prompt avec l'historique
            function_prompt = self.get_function_calling_prompt(prompt, self.execution_history)
            
            try:
                # G√©n√©rer la r√©ponse
                print("ü§î R√©flexion en cours...")
                response = generateText(function_prompt)
                
                # Traiter la r√©ponse
                result, should_stop = self.process_llm_response(response, step)
                results.append(result)
                
                print(f"ÔøΩ R√©sultat : {result}")
                
                # V√©rifier si l'agent veut s'arr√™ter
                if should_stop:
                    print(f"\nüèÅ Agent arr√™t√© √† l'√©tape {step}")
                    break
                    
            except Exception as e:
                error_msg = f"‚ùå Erreur √† l'√©tape {step}: {str(e)}"
                print(error_msg)
                results.append(error_msg)
                break
        
        print("\n" + "=" * 60)
        print("üìä R√âSUM√â DE L'EX√âCUTION")
        print("=" * 60)
        
        for i, result in enumerate(results, 1):
            print(f"√âtape {i}: {result}")
        
        return results


def chat_interface():
    """Interface de chat avec l'agent"""
    print("ü§ñ Agent IA Mistral avec Function Calling Multi-√âtapes")
    print("üìã Fonctions disponibles : writeFile, launchPythonFile, stop")
    print("üîÑ Commandes sp√©ciales :")
    print("   - 'agent <demande>' : Lance l'agent multi-√©tapes")
    print("   - 'quit' : Quitter")
    print("=" * 60)
    
    agent = Agent()
    
    while True:
        try:
            user_input = input("\nüí¨ Vous: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q', 'bye']:
                print("üëã Au revoir!")
                break
            
            if not user_input:
                print("‚ùå Veuillez taper quelque chose...")
                continue
            
            # V√©rifier si c'est une demande d'agent multi-√©tapes
            if user_input.lower().startswith('agent '):
                task = user_input[6:]  # Enlever 'agent '
                max_steps = 5  # Par d√©faut 5 √©tapes
                agent.run_agent(task, max_steps)
            else:
                # Utilisation normale du chat
                print("ü§î R√©flexion en cours...")
                response = generateText(user_input)
                print(f"ü§ñ Assistant: {response}")
            
        except KeyboardInterrupt:
            print("\nüëã Au revoir!")
            break
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
            print("üîÑ R√©essayez...")


if __name__ == "__main__":
    chat_interface()
